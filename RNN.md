# Recurrent Neural Networks (RNN)

Feed-forward networks (the input is fed into the network and propagates through the hidden layers to the output layer.
There is no sense of order in the inputs.

With RNN, output data feed input data so that we have a sense of order

RNN are able to remember past values so that they can improve their prediction. 

regular RNN can't have a Long Term memory because weights of initial inputs are vanishing during forward and back propagations.

Improved cells called LSTM give this ability to improve the memory of RNN.

Long Short Term Memory (LSTM)
